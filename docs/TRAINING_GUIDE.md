# è®­ç»ƒæŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨åŸºçº¿æ¨¡å‹è®­ç»ƒç³»ç»Ÿè¿›è¡Œç•ªèŒ„å¶æ–‘ç—…ç»†ç²’åº¦è¯†åˆ«ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®Œæˆæ•°æ®é¢„å¤„ç†ï¼š

```bash
python scripts/preprocess_data.py
python scripts/validate_preprocessing.py
```

### 2. æµ‹è¯•è®­ç»ƒç³»ç»Ÿ

è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆä½¿ç”¨å°‘é‡æ•°æ®å’Œ epochï¼‰ï¼š

```bash
python scripts/quick_train.py
```

### 3. å¼€å§‹å®Œæ•´è®­ç»ƒ

ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼š

```bash
python scripts/train_baseline.py
```

## ğŸ“‹ è®­ç»ƒå‚æ•°

### åŸºæœ¬å‚æ•°

| å‚æ•°              | é»˜è®¤å€¼ | è¯´æ˜                                    |
| ----------------- | ------ | --------------------------------------- |
| `--epochs`        | 100    | è®­ç»ƒè½®æ•°                                |
| `--learning_rate` | 0.001  | å­¦ä¹ ç‡                                  |
| `--weight_decay`  | 1e-4   | æƒé‡è¡°å‡                                |
| `--dropout_rate`  | 0.5    | Dropout æ¯”ç‡                            |
| `--optimizer`     | adam   | ä¼˜åŒ–å™¨ (adam/sgd)                       |
| `--scheduler`     | step   | å­¦ä¹ ç‡è°ƒåº¦å™¨ (step/cosine/plateau/none) |

### æ—©åœå‚æ•°

| å‚æ•°               | é»˜è®¤å€¼ | è¯´æ˜         |
| ------------------ | ------ | ------------ |
| `--early_stopping` | False  | æ˜¯å¦å¯ç”¨æ—©åœ |
| `--patience`       | 15     | æ—©åœå®¹å¿è½®æ•° |
| `--min_delta`      | 0.001  | æœ€å°æ”¹å–„å¹…åº¦ |

### å…¶ä»–å‚æ•°

| å‚æ•°                | é»˜è®¤å€¼            | è¯´æ˜             |
| ------------------- | ----------------- | ---------------- |
| `--experiment_name` | resnet50_baseline | å®éªŒåç§°         |
| `--seed`            | 42                | éšæœºç§å­         |
| `--freeze_backbone` | False             | æ˜¯å¦å†»ç»“éª¨å¹²ç½‘ç»œ |
| `--resume`          | None              | ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ |

## ğŸ¯ è®­ç»ƒç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ

```bash
python scripts/train_baseline.py \
    --epochs 50 \
    --learning_rate 0.001 \
    --experiment_name "baseline_50epochs"
```

### å¯ç”¨æ—©åœçš„è®­ç»ƒ

```bash
python scripts/train_baseline.py \
    --epochs 100 \
    --early_stopping \
    --patience 10 \
    --experiment_name "baseline_early_stop"
```

### å†»ç»“éª¨å¹²ç½‘ç»œçš„è®­ç»ƒ

```bash
python scripts/train_baseline.py \
    --freeze_backbone \
    --epochs 30 \
    --learning_rate 0.01 \
    --experiment_name "baseline_frozen"
```

### ä½¿ç”¨ä¸åŒä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨

```bash
python scripts/train_baseline.py \
    --optimizer sgd \
    --scheduler cosine \
    --learning_rate 0.01 \
    --experiment_name "baseline_sgd_cosine"
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```bash
python scripts/train_baseline.py \
    --resume "outputs/models/baseline_experiment/checkpoint_epoch_20.pth" \
    --experiment_name "baseline_resumed"
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨ä»¥ä¸‹ä½ç½®ç”Ÿæˆæ–‡ä»¶ï¼š

### æ¨¡å‹æ–‡ä»¶

- `outputs/models/{experiment_name}/`
  - `checkpoint_epoch_*.pth` - å®šæœŸä¿å­˜çš„æ£€æŸ¥ç‚¹
  - `best_checkpoint_epoch_*.pth` - æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹
  - `training_history.json` - è®­ç»ƒå†å²è®°å½•

### æ—¥å¿—æ–‡ä»¶

- `outputs/logs/{experiment_name}/`
  - TensorBoard æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœå®‰è£…äº† tensorboardï¼‰

### ç»“æœæ–‡ä»¶

- `outputs/results/{experiment_name}_results.json` - è®­ç»ƒç»“æœæ‘˜è¦

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### 1. æ§åˆ¶å°è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå®æ—¶æ˜¾ç¤ºï¼š

- æ¯ä¸ª epoch çš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±/å‡†ç¡®ç‡
- å­¦ä¹ ç‡å˜åŒ–
- è®­ç»ƒæ—¶é—´
- æœ€ä½³éªŒè¯å‡†ç¡®ç‡

### 2. TensorBoardï¼ˆå¯é€‰ï¼‰

å¦‚æœå®‰è£…äº† tensorboardï¼Œå¯ä»¥å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼š

```bash
# å®‰è£…tensorboard
pip install tensorboard

# å¯åŠ¨TensorBoard
tensorboard --logdir outputs/logs
```

### 3. æ—¥å¿—æ–‡ä»¶

è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `outputs/logs/` ç›®å½•ä¸­ã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**

   - å‡å° batch_sizeï¼šä¿®æ”¹ `src/config/config.py` ä¸­çš„ `BATCH_SIZE`
   - å‡å°‘ num_workersï¼šä¿®æ”¹ `NUM_WORKERS`

2. **è®­ç»ƒé€Ÿåº¦æ…¢**

   - åœ¨ CPU ä¸Šè®­ç»ƒè¾ƒæ…¢ï¼Œè€ƒè™‘ä½¿ç”¨ GPU
   - å‡å°‘æ•°æ®å¢å¼ºæ“ä½œ

3. **TensorBoard è­¦å‘Š**

   - å®‰è£… tensorboardï¼š`pip install tensorboard`
   - æˆ–å¿½ç•¥è­¦å‘Šï¼Œä¸å½±å“è®­ç»ƒ

4. **æ¨¡å‹ä¸æ”¶æ•›**
   - è°ƒæ•´å­¦ä¹ ç‡
   - æ£€æŸ¥æ•°æ®è´¨é‡
   - å°è¯•ä¸åŒçš„ä¼˜åŒ–å™¨

### è°ƒè¯•æ¨¡å¼

ä½¿ç”¨å°æ•°æ®é›†å¿«é€Ÿæµ‹è¯•ï¼š

```bash
python scripts/quick_train.py
```

## ğŸ“ å®éªŒè®°å½•

å»ºè®®ä¸ºæ¯æ¬¡å®éªŒè®°å½•ï¼š

- å®éªŒç›®çš„
- å‚æ•°è®¾ç½®
- æœ€ç»ˆç»“æœ
- è§‚å¯Ÿå’Œç»“è®º

ç¤ºä¾‹å®éªŒè®°å½•ï¼š

```
å®éªŒåç§°: baseline_50epochs
ç›®çš„: å»ºç«‹åŸºçº¿æ€§èƒ½
å‚æ•°: epochs=50, lr=0.001, optimizer=adam
ç»“æœ: æœ€ä½³éªŒè¯å‡†ç¡®ç‡ 85.2%
è§‚å¯Ÿ: åœ¨ç¬¬35è½®è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œä¹‹åå¼€å§‹è¿‡æ‹Ÿåˆ
ç»“è®º: å»ºè®®ä½¿ç”¨æ—©åœæœºåˆ¶
```

## ğŸ¯ ä¸‹ä¸€æ­¥

å®ŒæˆåŸºçº¿æ¨¡å‹è®­ç»ƒåï¼Œå¯ä»¥ï¼š

1. åˆ†æè®­ç»ƒç»“æœå’Œæ¨¡å‹æ€§èƒ½
2. å®ç°æ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹
3. è¿›è¡Œæ¨¡å‹å¯¹æ¯”å’Œæ¶ˆèå®éªŒ
4. ä¼˜åŒ–è¶…å‚æ•°
5. è¿›è¡Œæ¨¡å‹é›†æˆ
