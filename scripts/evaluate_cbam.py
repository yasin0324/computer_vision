#!/usr/bin/env python3
"""
CBAMæ¨¡å‹è¯„ä¼°è„šæœ¬
è¯„ä¼°è®­ç»ƒå¥½çš„CBAMæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
"""

import os
import sys
import torch
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.models.attention_models import ResNetCBAM
from src.data.dataset import TomatoSpotDataset
from src.config.config import Config

def evaluate_model(model, test_loader, device, class_names):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    all_predictions = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="è¯„ä¼°ä¸­"):
            # å¤„ç†ä¸åŒçš„æ•°æ®åŠ è½½å™¨è¿”å›æ ¼å¼
            if len(batch) == 2:
                images, labels = batch
            elif len(batch) == 3:
                images, labels, _ = batch
            else:
                raise ValueError(f"Unexpected batch format with {len(batch)} elements")
            
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))
    
    # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
    report = classification_report(
        all_labels, all_predictions, 
        target_names=class_names, 
        output_dict=True
    )
    
    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_predictions)
    
    return {
        'accuracy': accuracy,
        'predictions': all_predictions,
        'labels': all_labels,
        'probabilities': all_probs,
        'classification_report': report,
        'confusion_matrix': cm
    }

def plot_confusion_matrix(cm, class_names, save_path):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('CBAM æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹ç±»åˆ«')
    plt.ylabel('çœŸå®ç±»åˆ«')
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

def main():
    parser = argparse.ArgumentParser(description='è¯„ä¼°CBAMæ¨¡å‹')
    parser.add_argument('--model_path', type=str, 
                       default='outputs/models/resnet50_cbam_from_baseline/best_checkpoint_epoch_14.pth',
                       help='CBAMæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--output_dir', type=str, 
                       default='outputs/cbam_evaluation',
                       help='è¯„ä¼°ç»“æœè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ” CBAMæ¨¡å‹æµ‹è¯•é›†è¯„ä¼°")
    print("=" * 60)
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åŠ è½½é…ç½®
    config = Config()
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®å˜æ¢
    test_transform = transforms.Compose([
        transforms.Resize((config.INPUT_SIZE, config.INPUT_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
    data_dir = Path("data/processed")
    test_df = pd.read_csv(data_dir / "test_split.csv")
    
    class_names = list(config.TARGET_CLASSES.values())
    label_to_idx = {label: idx for idx, label in enumerate(class_names)}
    
    test_dataset = TomatoSpotDataset(test_df, test_transform, label_to_idx)
    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False,
                           num_workers=config.NUM_WORKERS, pin_memory=True)
    
    print(f"æµ‹è¯•æ•°æ®é›†å¤§å°: {len(test_dataset)}")
    
    # åˆ›å»ºCBAMæ¨¡å‹
    print("ğŸ—ï¸ åˆ›å»ºCBAMæ¨¡å‹...")
    model = ResNetCBAM(
        num_classes=config.NUM_CLASSES,
        reduction=16,
        dropout_rate=0.7
    )
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡: {args.model_path}")
    checkpoint = torch.load(args.model_path, map_location='cpu')
    model.model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸš€ å¼€å§‹æµ‹è¯•é›†è¯„ä¼°...")
    results = evaluate_model(model, test_loader, device, class_names)
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    cm_path = os.path.join(args.output_dir, "confusion_matrix.png")
    plot_confusion_matrix(results['confusion_matrix'], class_names, cm_path)
    print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_path}")
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š CBAMæ¨¡å‹è¯„ä¼°ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"æµ‹è¯•å‡†ç¡®ç‡: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
    print(f"æµ‹è¯•æ ·æœ¬æ€»æ•°: {len(results['labels'])}")
    
    # è®¡ç®—é”™è¯¯åˆ†ç±»æ ·æœ¬æ•°
    misclassified_count = np.sum(np.array(results['labels']) != np.array(results['predictions']))
    print(f"é”™è¯¯åˆ†ç±»æ ·æœ¬: {misclassified_count}")
    print(f"é”™è¯¯ç‡: {(1-results['accuracy'])*100:.2f}%")
    
    print(f"\nå„ç±»åˆ«æ€§èƒ½:")
    for class_name in class_names:
        metrics = results['classification_report'][class_name]
        print(f"  {class_name}:")
        print(f"    ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
        print(f"    å¬å›ç‡: {metrics['recall']:.4f}")
        print(f"    F1åˆ†æ•°: {metrics['f1-score']:.4f}")
    
    # ä¿å­˜æœ€ç»ˆç»“æœæŠ¥å‘Š
    report_path = os.path.join(args.output_dir, 'cbam_final_results.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# CBAMæ¨¡å‹æœ€ç»ˆè¯„ä¼°ç»“æœ\n\n")
        f.write("## æ¨¡å‹ä¿¡æ¯\n")
        f.write(f"- æ¨¡å‹ç±»å‹: ResNet50 + CBAM\n")
        f.write(f"- æ£€æŸ¥ç‚¹: {args.model_path}\n")
        f.write(f"- æ³¨æ„åŠ›æœºåˆ¶: é€šé“æ³¨æ„åŠ› + ç©ºé—´æ³¨æ„åŠ›\n")
        f.write(f"- é™ç»´æ¯”ä¾‹: 16\n\n")
        
        f.write("## æµ‹è¯•é›†æ€§èƒ½\n")
        f.write(f"- **æµ‹è¯•å‡†ç¡®ç‡**: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\n")
        f.write(f"- **æµ‹è¯•æ ·æœ¬æ€»æ•°**: {len(results['labels'])}\n")
        f.write(f"- **é”™è¯¯åˆ†ç±»æ ·æœ¬**: {misclassified_count}\n")
        f.write(f"- **é”™è¯¯ç‡**: {(1-results['accuracy'])*100:.2f}%\n\n")
        
        f.write("## å„ç±»åˆ«è¯¦ç»†æ€§èƒ½\n")
        f.write("| ç±»åˆ« | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° |\n")
        f.write("|------|--------|--------|--------|\n")
        for class_name in class_names:
            metrics = results['classification_report'][class_name]
            f.write(f"| {class_name} | {metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['f1-score']:.4f} |\n")
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print("ğŸ‰ CBAMæ¨¡å‹è¯„ä¼°å®Œæˆ!")

if __name__ == "__main__":
    main() 